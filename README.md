# Ai_enabled_customer_support_bot
# AI Customer Support Chatbot Project

## Overview

This project implements an AI-powered customer support chatbot leveraging Google Gemini, a generative language model by Google. The chatbot is designed to answer user queries by combining company-specific FAQ data, conversational context, and built-in escalation mechanisms to route complex issues to human agents.

The system integrates multiple components to provide a conversational AI that is both responsive and aware of company policies and practices. It is ideal for usage in customer service environments where immediate and accurate assistance is needed, but human handoff is available for escalated concerns.

---

## Project Components and Architecture

### 1. **Google Gemini AI Integration**

The core of chatbot response generation is Google Gemini, an advanced large language model. The system prepares prompts for Gemini that include:

- User's current query
- Conversation history
- Relevant company data (e.g., FAQs, service details)

Gemini generates a text response based on all this information, enabling context-aware, meaningful replies.

### 2. **FAQ Handler**

To ground the chatbot responses in verified company data and reduce API costs and latency, the system first attempts to find answers in an FAQ dataset (`faqs.json`). The FAQHandler:

- Loads the dataset on startup or first use.
- Performs exact and fuzzy matching for user queries.
- Returns a matched FAQ answer to avoid unnecessary LLM calls.
- Provides a helpful fallback prompt guiding Gemini if no match is available.

### 3. **Contextual Memory and Prompt Construction**

The chatbot maintains conversation history and contextual memory relevant to the current session. This context is combined with company data and user queries to construct rich prompts that inform Gemini of prior interactions and company rules.

Prompt construction uses structured formats with roles (`system`, `user`, `assistant`) to clearly separate input types, aiding Geminiâ€™s understanding.

### 4. **Escalation Handling**

If Gemini or the FAQ handler responds with fallback or inadequate information, or when a user explicitly requests human support, the system triggers escalation:

- Marks the conversation as escalated.
- Notifies human customer support asynchronously.
- Provides users with appropriate messages about human agent assistance.

Escalation detection uses keyword-based regex patterns matching common fallback phrases or explicit escalation requests.

### 5. **Next Actions Suggestions**

Post-response, the system asks Gemini to provide up to 3 relevant next steps or recommendations for the user to proceed with their issue. These are presented alongside the chatbot's reply to enhance user guidance.

---

## Detailed File Structure

- **`app/api/routes.py`**  
  Implements FastAPI endpoints handling chat queries, session creation and management, summarization, and next action retrieval.  
  Coordinates between FAQ, LLMClient, escalation handler, and session manager.

- **`app/services/llm_integration.py`**  
  Contains the `LLMClient` class, which manages Gemini API calls including retries, response formatting, and escalation logic.

- **`app/services/faq_handler.py`**  
  Loads and manages FAQ dataset; performs fuzzy matching; provides fallback prompts for unmatched queries.

- **`app/services/escalation_handler.py`**  
  Provides mechanisms to detect fallback responses and trigger escalation notifications to human agents.

- **`app/utils/prompts.py`**  
  Contains prompt template constants and prompt-building helper functions to format conversation data and manage escalation detection.

- **`data/faqs.json`**  
  JSON file containing company-specific frequently asked questions, policies, and key service information.

- **Other supporting modules and configuration files.**

---

## Setup Instructions

### 1. Clone and Install
git clone https://github.com/yourusername/ai-customer-support-chatbot.git
cd ai-customer-support-chatbot
pip install -r requirements.txt


### 2. Configure Environment

Set your Google Gemini API key:
export GEMINI_API_KEY="your_gemini_api_key_here"


(or set equivalent environment variables in your OS or deployment environment)

### 3. Prepare FAQ Data

Make sure `data/faqs.json` contains valid company FAQ entries in JSON format with key-value pairs for questions and answers.

### 4. Start the Server

Run the FastAPI backend:

uvicorn app.main:app --reload


The server will run locally on `http://localhost:8000`.

---

## Usage Guide

- Use `/api/query` POST requests to send user queries. Include optional session IDs to maintain conversation context.
- The chatbot first tries to answer using FAQ data, then falls back on Gemini-based generation augmented with contextual memory and company data.
- Escalation and next action suggestions are integrated into responses based on fallback triggers and conversation analysis.

---

## How the System Works (Example Flow)

1. A user sends the query "How do I reset my password?".
2. The FAQ handler searches for matching questions. Finds a relevant entry and returns the answer directly.
3. If no FAQ match, the system constructs a conversational prompt including past chat history, company data, and user query.
4. Gemini generates a detailed response respecting company policies.
5. If the response is unsatisfactory (detected via fallback keywords), escalation is triggered:
   - User is informed of human support intervention.
   - Support team is notified asynchronously.
6. Next action suggestions are generated for user guidance.

---

## Additional Notes

- **Prompt Optimization:**  
  To reduce latency, the system limits company data injected into prompts to key information like name, location, and services rather than full FAQs.
  
- **Retry Mechanism:**  
  Gemini API calls have configurable retries with exponential backoff to improve reliability in case of transient failures.

- **Logging and Debugging:**  
  Extensive logging captures API call attempts, prompt details, escalation events, and errors.

---

## Future Enhancements

- Adding multi-language support for international users.
- Improving intent detection to better classify query types.
- Integrating with ticketing systems to automate escalation workflows.
- Developing a frontend UI for real-time chat interaction.

---

## Contact and Support

For questions, bug reports, or contributions, please contact:

- Your Name  
- Email: your.email@example.com  
- GitHub: https://github.com/yourusername
