# AI Customer Support Bot - Project Documentation

## Objective

A customer care support bot that emulates human customer interactions and has capabilities of simulating a realistic customer experience by addressing FAQs, escalation cases and has deep integration of LLM, contextual memory and session management. The system is automated to respond to customer queries and allows easy handover to human agents where a human is required.



---

## Scope of Work

- **Input:**  
  - FAQs of company in direct question-answering format.  
  - Customers requests coming through REST API calls.

- **Contextual Memory:**  
  - Keeps a history of multi-turn conversation to give appropriate responses that can be contextually relevant.

- **Escalation Handling:**  
  - Unanswered queries or simulated complex queries, which are sent to human support automatically.

- **Frontend Chat Interface:**  
  - A convenient and interactive chat interface with a real-time interface to interact with AI and humans.

---

## Technical Architecture

### Backend API

- Uses FastAPI to implement REST endpoints to offer query processing and session creation and management, conversation summarization, and next action retrieval.
- Maintains persistent session and conversation data using a database backend.

## Database

- MongoDB Atlas is a NoSQL database that is hosted on the cloud and used in the system to store session and conversation data. MongoDB was selected due to its ability to be flexible to dynamic and schema-less data formats that match chat conversation logs, scaling well to use with cloud hosting, and supporting asynchronous Python data access with Motor.
- Discussions, session documentation and contextual memory are archived in special collections that allow persistence through server re-boots and retrieval of sessions through client interactions.
(Nothing was mentioned about the type of database so i used Mongodb because :
- Adapts well to documents of chat conversations that are flexible in format based on JSON.
- Easy to implement in less time and Grows with ease in terms of user base and data volume.
- Supports Motor driver asynchronous access patterns to FastAPI compatibility.
- Offloads session storage from application memory to some type of more durable storage, which avoids data loss on restarts and provides better performance.)

### LLM Integration

- Gemini 2.5-flash model used by Google is selectively applied to improve and add to AI-generated answers, and the main conversational intelligence and information processing is conducted through our own algorithms and contextual memory system.
- High level of prompt engineering injects structured dialogue and succinct data about the company.
- Implements multi-step processing including retries with exponential backoff.

### FAQ Handling

- FAQs company loads and indexes with exact matching, fuzzy matching.
- Gives quick and accurate responses to the FAQ data set whenever possible.
- Fallback to answer generated by LLM in the case of no FAQ match, and cover all the cases.

### Contextual Memory & Company Data

- Injects historical conversation that was created with conversation_history and relevant company policy snippets dynamically into prompts to ground LLM-generated responses.
This helps to give more specific answer.

### Escalation System

- Detects fallback, ambiguous, or explicit escalation requests with the help of regex patterns defined in the prompts.py as escalation_phrases.
- Generates escalation notes with all previous chat history and asynchronously notifies human support teams.
- Provides clear user communication around escalation status with all details .
- Upon escalation all previous chats are shared for the context and better resolution .

### Next Actions Suggestion

- With every query it generates AI-recommended  next steps after the main response(available at the bottom of page with the name of suggested actions .)
- Increases effectiveness in guiding and interacting with users.

### Frontend Chat Interface

- Chat user interface with real-time application and backend API to enable smooth interaction between the end-user.
- frontend well supports multi-turn dialog handling and session management.
- Shows AI responses, suggestion buttons, and escalation notifications handled by careful parsing of response format.

### Enhanced Intent Recognition

- Introduces keyword and pattern-based user intent detection of user queries such as escalation queries.
- Enables fined routing of queries and user requests to enhance AI-human handoff.



### Ticketing System Integration

- Connects escalations with the human support ticketing workflows.

---

## Project File Structure

- `app/api/routes.py` — FastAPI REST API endpoints orchestrating chatbot functions.
- `app/services/faq_handler.py` — FAQ dataset management with query matching and fallback prompts.
- `app/services/llm_integration.py` — Google Gemini API client, including prompt formatting and escalation handling.
- `app/services/escalation_handler.py` — Detects escalation need and manages support team notifications.
- `app/services/chat_frontend.py` (or equivalent) — Implements real-time chat UI backend integration.
- `app/utils/prompts.py` — Contains prompt template texts and helper functions for prompt construction and escalation detection.
- `data/faqs.json` — Company FAQ dataset in JSON format with structured question-answer pairs.
- Configuration files and dependencies manifest (e.g., `requirements.txt`).

---

## Setup and Deployment Instructions

1. Clone the repository:
git clone https://github.com/yourusername/ai-customer-support-chatbot.git
cd ai-customer-support-chatbot


2. Install required Python packages:
pip install -r requirements.txt


3. Set environment variables:
export GEMINI_API_KEY="your_google_gemini_api_key"
Mongo_Db_URL or whatever database is used .
I have use MongoDb atlas online database.


4. Ensure the `data/faqs.json` file is properly populated with your company-specific FAQs and policies.

5. Launch the backend API service:
uvicorn app.main:app --reload


6. Launch frontend interface server (if applicable), or integrate with your existing frontend.

---

## Usage Instructions

- Send customer requests to endpoint of  `/api/query` , which can and may include session id to provide context of that conversation.
- Use session endpoints to retrieve different conversation history summaries and suggestions with the help of REST.
- Monitor escalations in logs created in your respective logging service or via your integrated support ticketing system (optional you can add it according to the need.)
- Use the chat interface to support real time interactions providing conversational context and flow of escalation.

---

## Functional Workflow

1. Exact or fuzzy hits against the FAQ dataset are first done on incoming queries.
2. In case no answer in the FAQ, prompt is formulated using history of conversation and company information.
3. To support the core AI response system created based on custom conversation logic and FAQ resolution, Google Gemini is called upon to help with generating responses where necessary.
4. The text of the response is analyzed to identify fallback or escalation conditions.
5. The escalations cause the user notification and the creation of human support tickets to be created asynchronously.
6. The next actions presented by AI are proactive.
7. Multi-turn_conversations maintain context over sessions for better responses.
8. AI responses, suggestions, and escalation status are displayed in the frontend chat in a clear and seamlessly human-transferable way.

---

## Evaluation Criteria Alignment

- **Accuracy and Relevance:**  
  Assures customer inquiries receive accurate and the right answers based on company information.

- **Session and State Management:**  
  It supports different/rich multi-turn dialogs with persistent context for better service .

- **Robust LLM Integration:**  
  Smooth, reliable communication with Gemini if stuck at any place (this ensures our bot doesnt fail at any scenario)including retry policies and prompt engineering.

- **Clean, Modular Codebase:**  
  Clearly separated responsibilities in API, LLM integration, FAQ handling, and escalation logic this helps in better integration and management of resources.

- **User Experience:**  
  Genial front end chat interaction with next steps visibility and transparency of escalation.

---

## Deliverables Summary

- Complete source code committed in github repo .
- Readme file explaining about the project .
- Demo video showing the capabilities of a chatbot such as escalation and management.


---

## Thank You

This project was developed by Himanshu

---

## Scrrenshots of chats showing some of the features of ai powered support bot .

<img width="640" height="964" alt="Screenshot 2025-10-13 132830" src="https://github.com/user-attachments/assets/bb250590-28b8-4122-b946-4d913e55c24a" />

<img width="615" height="964" alt="Screenshot 2025-10-13 132457" src="https://github.com/user-attachments/assets/19ed371a-40ab-4c88-8f9c-8619b67e6129" />

<img width="613" height="962" alt="Screenshot 2025-10-13 132533" src="https://github.com/user-attachments/assets/1cf3f975-839a-4e95-9e6c-443cd36b4647" />

<img width="621" height="962" alt="Screenshot 2025-10-13 132606" src="https://github.com/user-attachments/assets/8e2170e0-0fa2-40eb-8c18-5d6a34289072" />







